# Estudo de caso 2
## Metodologia

Para este estudo de caso, coletamos os dados do artigo de Martins et al. (2023). Comparamos ainda com os resultados do artigo de Convolutional Neural Networks de Santos et al. (2023; 10.1007/978-3-031-42715-2_11).

Ao todo, 1112 peptídeos foram coletados. Eles são classificados em cinco classes:
- S0	(503 entradas)
- S1 	(184 entradas)
- S112 	(161 entradas)
- S151 	(142 entradas)
- S162 	(122 entradas)

A seguir, executamos o script "lista_pdbs.py", que gerou o arquivo "input_cs2.csv" com o endereço de cada um dos PDBs.

Signa foi executado usando o seguinte comando:
~~~
signa.read_csv(
 	csv_file='./docs/case_studies/cs2/input_cs2.csv', 
 	signa_type='signa_charge', 
    cumulative=False,
    forcefield='AMBER',
 	output='./docs/case_studies/cs2/output.csv',
    cutoff_limit=12
)
~~~

O resultado foi disposto em "output.csv". Manualmente abrimos esse arquivo e removemos todos os trechos "./docs/case_studies/cs2/pdb/" e ".pdb". Por fim, substituímos "/" por ",".

Adicionamos o seguinte cabeçalho:
~~~
cluster,entry,0.2-0.25,0.2-0.5,0.2-0.75,0.2-1.0,0.2-1.25,0.2-1.5,0.2-1.75,0.2-2.0,0.4-0.25,0.4-0.5,0.4-0.75,0.4-1.0,0.4-1.25,0.4-1.5,0.4-1.75,0.4-2.0,0.6-0.25,0.6-0.5,0.6-0.75,0.6-1.0,0.6-1.25,0.6-1.5,0.6-1.75,0.6-2.0,0.8-0.25,0.8-0.5,0.8-0.75,0.8-1.0,0.8-1.25,0.8-1.5,0.8-1.75,0.8-2.0,1.0-0.25,1.0-0.5,1.0-0.75,1.0-1.0,1.0-1.25,1.0-1.5,1.0-1.75,1.0-2.0,1.2-0.25,1.2-0.5,1.2-0.75,1.2-1.0,1.2-1.25,1.2-1.5,1.2-1.75,1.2-2.0,1.4-0.25,1.4-0.5,1.4-0.75,1.4-1.0,1.4-1.25,1.4-1.5,1.4-1.75,1.4-2.0,1.6-0.25,1.6-0.5,1.6-0.75,1.6-1.0,1.6-1.25,1.6-1.5,1.6-1.75,1.6-2.0,1.8-0.25,1.8-0.5,1.8-0.75,1.8-1.0,1.8-1.25,1.8-1.5,1.8-1.75,1.8-2.0,2.0-0.25,2.0-0.5,2.0-0.75,2.0-1.0,2.0-1.25,2.0-1.5,2.0-1.75,2.0-2.0,2.2-0.25,2.2-0.5,2.2-0.75,2.2-1.0,2.2-1.25,2.2-1.5,2.2-1.75,2.2-2.0,2.4-0.25,2.4-0.5,2.4-0.75,2.4-1.0,2.4-1.25,2.4-1.5,2.4-1.75,2.4-2.0,2.6-0.25,2.6-0.5,2.6-0.75,2.6-1.0,2.6-1.25,2.6-1.5,2.6-1.75,2.6-2.0,2.8-0.25,2.8-0.5,2.8-0.75,2.8-1.0,2.8-1.25,2.8-1.5,2.8-1.75,2.8-2.0,3.0-0.25,3.0-0.5,3.0-0.75,3.0-1.0,3.0-1.25,3.0-1.5,3.0-1.75,3.0-2.0,3.2-0.25,3.2-0.5,3.2-0.75,3.2-1.0,3.2-1.25,3.2-1.5,3.2-1.75,3.2-2.0,3.4-0.25,3.4-0.5,3.4-0.75,3.4-1.0,3.4-1.25,3.4-1.5,3.4-1.75,3.4-2.0,3.6-0.25,3.6-0.5,3.6-0.75,3.6-1.0,3.6-1.25,3.6-1.5,3.6-1.75,3.6-2.0,3.8-0.25,3.8-0.5,3.8-0.75,3.8-1.0,3.8-1.25,3.8-1.5,3.8-1.75,3.8-2.0,4.0-0.25,4.0-0.5,4.0-0.75,4.0-1.0,4.0-1.25,4.0-1.5,4.0-1.75,4.0-2.0,4.2-0.25,4.2-0.5,4.2-0.75,4.2-1.0,4.2-1.25,4.2-1.5,4.2-1.75,4.2-2.0,4.4-0.25,4.4-0.5,4.4-0.75,4.4-1.0,4.4-1.25,4.4-1.5,4.4-1.75,4.4-2.0,4.6-0.25,4.6-0.5,4.6-0.75,4.6-1.0,4.6-1.25,4.6-1.5,4.6-1.75,4.6-2.0,4.8-0.25,4.8-0.5,4.8-0.75,4.8-1.0,4.8-1.25,4.8-1.5,4.8-1.75,4.8-2.0,5.0-0.25,5.0-0.5,5.0-0.75,5.0-1.0,5.0-1.25,5.0-1.5,5.0-1.75,5.0-2.0,5.2-0.25,5.2-0.5,5.2-0.75,5.2-1.0,5.2-1.25,5.2-1.5,5.2-1.75,5.2-2.0,5.4-0.25,5.4-0.5,5.4-0.75,5.4-1.0,5.4-1.25,5.4-1.5,5.4-1.75,5.4-2.0,5.6-0.25,5.6-0.5,5.6-0.75,5.6-1.0,5.6-1.25,5.6-1.5,5.6-1.75,5.6-2.0,5.8-0.25,5.8-0.5,5.8-0.75,5.8-1.0,5.8-1.25,5.8-1.5,5.8-1.75,5.8-2.0,6.0-0.25,6.0-0.5,6.0-0.75,6.0-1.0,6.0-1.25,6.0-1.5,6.0-1.75,6.0-2.0,6.2-0.25,6.2-0.5,6.2-0.75,6.2-1.0,6.2-1.25,6.2-1.5,6.2-1.75,6.2-2.0,6.4-0.25,6.4-0.5,6.4-0.75,6.4-1.0,6.4-1.25,6.4-1.5,6.4-1.75,6.4-2.0,6.6-0.25,6.6-0.5,6.6-0.75,6.6-1.0,6.6-1.25,6.6-1.5,6.6-1.75,6.6-2.0,6.8-0.25,6.8-0.5,6.8-0.75,6.8-1.0,6.8-1.25,6.8-1.5,6.8-1.75,6.8-2.0,7.0-0.25,7.0-0.5,7.0-0.75,7.0-1.0,7.0-1.25,7.0-1.5,7.0-1.75,7.0-2.0,7.2-0.25,7.2-0.5,7.2-0.75,7.2-1.0,7.2-1.25,7.2-1.5,7.2-1.75,7.2-2.0,7.4-0.25,7.4-0.5,7.4-0.75,7.4-1.0,7.4-1.25,7.4-1.5,7.4-1.75,7.4-2.0,7.6-0.25,7.6-0.5,7.6-0.75,7.6-1.0,7.6-1.25,7.6-1.5,7.6-1.75,7.6-2.0,7.8-0.25,7.8-0.5,7.8-0.75,7.8-1.0,7.8-1.25,7.8-1.5,7.8-1.75,7.8-2.0,8.0-0.25,8.0-0.5,8.0-0.75,8.0-1.0,8.0-1.25,8.0-1.5,8.0-1.75,8.0-2.0,8.2-0.25,8.2-0.5,8.2-0.75,8.2-1.0,8.2-1.25,8.2-1.5,8.2-1.75,8.2-2.0,8.4-0.25,8.4-0.5,8.4-0.75,8.4-1.0,8.4-1.25,8.4-1.5,8.4-1.75,8.4-2.0,8.6-0.25,8.6-0.5,8.6-0.75,8.6-1.0,8.6-1.25,8.6-1.5,8.6-1.75,8.6-2.0,8.8-0.25,8.8-0.5,8.8-0.75,8.8-1.0,8.8-1.25,8.8-1.5,8.8-1.75,8.8-2.0,9.0-0.25,9.0-0.5,9.0-0.75,9.0-1.0,9.0-1.25,9.0-1.5,9.0-1.75,9.0-2.0,9.2-0.25,9.2-0.5,9.2-0.75,9.2-1.0,9.2-1.25,9.2-1.5,9.2-1.75,9.2-2.0,9.4-0.25,9.4-0.5,9.4-0.75,9.4-1.0,9.4-1.25,9.4-1.5,9.4-1.75,9.4-2.0,9.6-0.25,9.6-0.5,9.6-0.75,9.6-1.0,9.6-1.25,9.6-1.5,9.6-1.75,9.6-2.0,9.8-0.25,9.8-0.5,9.8-0.75,9.8-1.0,9.8-1.25,9.8-1.5,9.8-1.75,9.8-2.0,10.0-0.25,10.0-0.5,10.0-0.75,10.0-1.0,10.0-1.25,10.0-1.5,10.0-1.75,10.0-2.0,10.2-0.25,10.2-0.5,10.2-0.75,10.2-1.0,10.2-1.25,10.2-1.5,10.2-1.75,10.2-2.0,10.4-0.25,10.4-0.5,10.4-0.75,10.4-1.0,10.4-1.25,10.4-1.5,10.4-1.75,10.4-2.0,10.6-0.25,10.6-0.5,10.6-0.75,10.6-1.0,10.6-1.25,10.6-1.5,10.6-1.75,10.6-2.0,10.8-0.25,10.8-0.5,10.8-0.75,10.8-1.0,10.8-1.25,10.8-1.5,10.8-1.75,10.8-2.0,11.0-0.25,11.0-0.5,11.0-0.75,11.0-1.0,11.0-1.25,11.0-1.5,11.0-1.75,11.0-2.0,11.2-0.25,11.2-0.5,11.2-0.75,11.2-1.0,11.2-1.25,11.2-1.5,11.2-1.75,11.2-2.0,11.4-0.25,11.4-0.5,11.4-0.75,11.4-1.0,11.4-1.25,11.4-1.5,11.4-1.75,11.4-2.0,11.6-0.25,11.6-0.5,11.6-0.75,11.6-1.0,11.6-1.25,11.6-1.5,11.6-1.75,11.6-2.0,11.8-0.25,11.8-0.5,11.8-0.75,11.8-1.0,11.8-1.25,11.8-1.5,11.8-1.75,11.8-2.0,12.0-0.25,12.0-0.5,12.0-0.75,12.0-1.0,12.0-1.25,12.0-1.5,12.0-1.75,12.0-2.0
~~~

Os dados foram importados para o Orange Data Mining. 
Foram utilizados cinco diferentes algoritmos para construção dos modelos:
- kNN (k=2; metric: Manhattan; weight: by distances)
- Redes neurais (neurons: 100; actvation: ReLu; solver: Adam; regularization: alpha=0.0001; max iteration: 200)
- SVM (cost: 1.00, regression loss epsilon: 0.1; kernel: linear; itetarion limit: 100; numerical tolerance: 0.001)
- Random Forest (trees: 10; subset limits: 5)
- Gradient Boosting (trees: 100; learning rate: 0.1; limit depth of individual trees: 3; split limit: 2)

Foi feito cross-validation (10-fold). Para avaliar os resultados, determinamos o AUC, CA, F1, Precision e Recall.

## Resultados

~~~
Model	Time	AUC	CA	F1	Prec	Recall
kNN	0.4	0.974	0.937	0.937	0.939	0.937
SVM	2.1	0.991	0.933	0.934	0.934	0.933
Random Forest	0.7	0.993	0.926	0.926	0.927	0.926
Neural Network	63.7	0.981	0.898	0.899	0.900	0.898
Gradient Boosting	115.5	0.998	0.968	0.968	0.968	0.968
~~~

